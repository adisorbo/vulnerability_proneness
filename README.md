# Replication Package for the paper entitled “Exposed! A Case Study on the Vulnerability-Proneness of Google Play Apps”

Description of the content:

1) the [data](data/) folder contains the **dataset.csv** file in which all the data collected for the apps considered in the study are          reported. While the data encompassed in this repository have been used to answer the three research questions stated in the paper        and can be used for replication purposes, it is worth noticing that only cumulative information about vulnerabilities -- and not        the specific vulnerabilities exhibited by each app --  is reported, to prevent the dataset from being used for malicious purposes. 
   In particular, for each considered app, in our [dataset](data/dataset.csv) we report the following information:
      - the app id (i.e., *app_id*)
      - the app's name (i.e., *Name*), 
      - the app's description (i.e, *Description*), 
      - the app's Play store category (i.e., *Category*), 
      - the app's average rating (i.e., *Rating*),
      - the number of users who rated the app (i.e., *Raters*), 
      - the number of installs (i.e, *Installs*), 
      - the app's size (i.e., *Size*),
      - the number of permissions required by the app (i.e., *Permissions*) 
      - the number of words in the app's description (i.e., *DescriptionLength*) 
      - the number of photos/screenshots appearing in the app's market webpage (i.e., *Screenshots*), 
      - whether the app contains ads (i.e., *ContainsAds*)
      - whether the app offers in-app purchases (i.e., *InAppPurchase*)
      - the list of permissions the app requires (i.e., the columns from *Location_approximate location (network-based)* to *Other_bind to a notification listener service*), 
      - the number of different types of vulnerabilities exhibited by the app (i.e., *all_vulns*).
  
      For answering RQ1, we used the information related to (i) the *Categories* of apps, (ii) the vulnerability-proneness levels (i.e.,   *all_vulns*), and (iii) the specific types of vulnerabilities found in apps (see the 
  [vulnerability types](https://github.com/adisorbo/vulnerability_proneness/wiki/Vulnerability-Types) that we considered in our study).   To answer RQ2, we used the information related to apps' (i) average *Rating*s, (ii) number of *Installs*, and (iii)          vulnerability-proneness levels (i.e., *all_vulns*).  

2) the [ml_experiments](ml_experiments) folder contains the *.arff* files related to the ML experiments performed in our RQ3. As            reported in the paper, in each experiment we used a different combination of features and the 10-fold cross-validation strategy to      train three machine learning algorithms (i.e., Naive Bayes, J48 and Random Forest). More specifically:
      - in the file [Experiment_1_appMarket_and_text_features.arff](ml_experiments/Experiment_1_appMarket_and_text_features.arff) app market and textual features (extracted from app names and descriptions) are considered;
      - in the file [Experiment_2_appMarket_features.arff](ml_experiments/Experiment_2_appMarket_features.arff) only app market features are considered;
      - in the file [Experiment_3_static_features.arff](ml_experiments/Experiment_3_static_features.arff) code-related features are considered (e.g., number of third party libraries, number of classes, etc.);
      - in the file [Experiment_4_app_market_and_static_and_text_features.arff](ml_experiments/Experiment_4_app_market_and_static_and_text_features.arff) app market, code-related, and textual features are considered;
      - in the file [Experiment_5_app_market_and_static_features.arff](ml_experiments/Experiment_5_app_market_and_static_features.arff) app marked and code-related features are considered;
